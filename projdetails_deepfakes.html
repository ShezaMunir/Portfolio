<!DOCTYPE HTML>
<!--
	Stellar by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>

<head>
	<title>Deepfake Audio Defense Dataset</title>
	<meta charset="utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
	<link rel="stylesheet" href="assets/css/main.css" />
	<noscript>
		<link rel="stylesheet" href="assets/css/noscript.css" />
	</noscript>
	<link rel="icon" type="image/svg+xml" href="images/logo.svg" />

</head>

<body class="is-preload">

	<!-- Wrapper -->
	<div id="wrapper">

		<!-- Header -->
		<header id="header">
			<h1>Deepfake Audio Defense Dataset</h1>
			<p>Constructing and Evaluating a Specialized Urdu Deepfake Audio Dataset</p>
		</header>

		<!-- Main -->
		<div id="main">

			<!-- Content -->
			<section id="content" class="main">

				<span class="image main"><img src="images/proj_deepfakes_dataset_distribution.jpg" alt=""
						style="padding: 20px;" /></span>
				<span class="image main"><img src="images/proj_deepfakes_main_photo.jpg" alt=""
						style="padding: 20px;" /></span>

				<h2>Motivation</h2>
				<p>The proliferation of deepfake audio, particularly in low-resource languages like Urdu, poses
					significant challenges for
					automatic speaker verification systems and has the potential to spread misinformation. Existing
					datasets for deepfake
					detection primarily focus on high-resource languages, leaving a critical gap in resources for
					languages like Urdu. This
					research aims to address this deficiency by creating a comprehensive Urdu deepfake audio dataset.
					The creation of
					synthetic datasets is crucial for developing robust detection models, but it must be done carefully
					to ensure the
					dataset's quality and representativeness.</p>
				<h2>Task</h2>
				<p>We set out to construct and evaluate a specialized Urdu deepfake audio dataset for deepfake
					detection. Our goal was to
					create a resource that would enable the training of robust detection models for Urdu, a low-resource
					language, while
					ensuring phonemic cover and balance comparable to established Urdu corpora. The task involved not
					only generating
					synthetic data but also rigorously evaluating its quality and trustworthiness to ensure its utility
					in real-world
					applications.</p>
				<h2>Action</h2>
				<p>We developed a dataset comprising 20,451 utterances of bonafide audio and 16,830 utterances of
					deepfake audio1
					. The deepfake samples were generated using two advanced text-to-speech models: Tacotron and VITS
					TTS. We conducted
					rigorous phonemic analysis to ensure the dataset's linguistic representativeness, comparing it with
					established Urdu
					corpora such as PRUS and PronouncUR. The phonemic analysis revealed strong correlations with
					Spearman's Rank Correlation
					coefficients of 0.977 and 0.958 when compared to PRUS and PronouncUR, respectively1
					. Additionally, we performed both qualitative and quantitative evaluations of the dataset, including
					human evaluation
					studies and machine learning-based assessments using models like AASIST-L and RawNet2.</p>
				<h2>Results</h2>
				<p>Our analysis validated the dataset's utility for training deepfake detection models. The Equal Error
					Rate (EER) obtained
					through the AASIST-L model was 0.495 for VITS TTS and 0.524 for Tacotron-generated audios,
					indicating the challenge in
					distinguishing between real and fake samples1
					. These results highlight the high quality of the synthetic data and the need for advanced
					countermeasures against audio
					deepfakes in low-resource languages. Human evaluation showed that approximately one in three fake
					audio samples were
					perceived as real, underscoring the potential risks of deepfake audio in spreading misinformation1
					. The t-SNE visualization and L2 norm comparisons further demonstrated the spectral similarities
					between bonafide and
					deepfake audios, emphasizing the sophistication of the generated synthetic data. These comprehensive
					evaluations
					contribute to the trustworthiness of systems trained on this dataset, as they provide a realistic
					and challenging
					benchmark for deepfake detection in Urdu.</p>
				<h2>Samples from the Dataset</h2>
				<div>
					<p>Bonafide (spoken/real audio): <br /> <audio controls
							src="audiosamples//bonafide_audio.wav"></audio></p>
					<p>TTS Generated (deepfake audio): <br /><audio controls src="audiosamples/TTS_audio.wav"></audio>
					</p>
					<p>Tacotron Generated (deepfake audio): <br /><audio controls
							src="audiosamples/Tacotron_audio.wav"></audio></p>
				</div>

				<ul class="actions">
					<li><a href="https://aclanthology.org/2024.findings-acl.861/" target="_blank"
							class="button">Paper</a>
					</li>
					<li><a href="https://huggingface.co/datasets/CSALT/deepfake_detection_dataset_urdu" target="_blank"
							class="button">HuggingFace</a></li>
					<!-- <li><a href="generic.html" target="_blank" class="button">Learn More</a></li> -->
				</ul>
				<h3>Media</h3>
				<div class="media-gallery">
					<img src="images/proj_deepfakes_group_photo.jpeg" alt="The Team at ACL 2024" width="200">
					<img src="images/proj_deepfakes_presenting.jpeg" alt="Presenting the Poster at ACL 2024">
				</div>
			</section>

		</div>

		<!-- Footer -->
		<footer id="footer">
			<section>
				<h2>Collaborations:</h2>
				<p>I'm always open to new opportunities and collaborations.<br />
					Feel free to reach out through any of the following channels:</p>
				<!-- <ul class="actions">
							<li><a href="generic.html" class="button">Learn More</a></li>
						</ul> -->
				<ul class="icons">
					<li><a href="https://x.com/sheza_munir" class="icon brands fa-twitter alt"><span
								class="label">Twitter</span></a>
					</li>
					<!-- <li><a href="#" class="icon brands fa-facebook-f alt"><span class="label">Facebook</span></a></li>
											<li><a href="#" class="icon brands fa-instagram alt"><span class="label">Instagram</span></a></li> -->
					<li><a href="https://github.com/ShezaMunir" class="icon brands fa-github alt"><span
								class="label">GitHub</span></a>
					</li>
					<li><a href="https://www.linkedin.com/in/shezamunir/" class="icon brands fa-linkedin alt"><span
								class="label">Dribbble</span></a></li>
				</ul>
			</section>
			<section>
				<h2>Get in touch!</h2>
				<dl class="alt">
					<dt>Address</dt>
					<dd>Ann Arbor, MI, USA</dd>
					<dt>Phone</dt>
					<dd>(734) 837-1252</dd>
					<dt>Email</dt>
					<dd><a href="shezamnr@umich.edu">shezamnr@umich.edu</a></dd>
				</dl>

			</section>
			<p class="copyright">&copy; Sheza Munir. Design: <a href="https://html5up.net">HTML5 UP</a>.</p>
		</footer>

	</div>

	<!-- Scripts -->
	<script src="assets/js/jquery.min.js"></script>
	<script src="assets/js/jquery.scrollex.min.js"></script>
	<script src="assets/js/jquery.scrolly.min.js"></script>
	<script src="assets/js/browser.min.js"></script>
	<script src="assets/js/breakpoints.min.js"></script>
	<script src="assets/js/util.js"></script>
	<script src="assets/js/main.js"></script>

</body>

</html>